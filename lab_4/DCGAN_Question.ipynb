{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjU61NLx9ySA"
   },
   "source": [
    "\n",
    "# Generative Adversarial Networks\n",
    "\n",
    "## DCGAN : Deep Convolutional Generative Adversarial Networks\n",
    "\n",
    "Scaling up Generative Adversarial Networks using Convolutional Neural Networks has always been quite difficult. Additionally, training of GANs is always difficult are require often several tips and tricks to obtain a desirable performance. \n",
    "\n",
    "The DCGAN is a specialised architecture that functions better by using some significant **architectural modifications** in implementing CNNs as compared to a normal CNN used in a supervised learning scenario [2]. Some of those modifications are as follows:\n",
    "\n",
    "- *Using an 'All-Convolutional Net' architecture:* Typically, CNNs are constructed using Max-pool operations. However, in DCGANs this is replaced with the use of strided and fractionally strided convolutions. This is done so that the network can learn its own spatial downsampling or upsampling.\n",
    "\n",
    "- *Eliminating fully connected layers at the top:* Does not use fully connected layers a the top of the convolutional features. Instead considers the reshaping of the latent data $\\mathbf{z}$ at the start of the generator network to reshaped into 4-dim tensor, and using a *flattening* operation at the end of the discriminator network.\n",
    "\n",
    "- *Using Batch-Normalization:* This normalizes the input to each unit to have zero mean and unit variance. This helps to deal with training problems. However, directly applying batch normalization to all layers results in sample oscillation and model instability. It shouldn't be applied on the generator output layer and on the discriminator input layer. \n",
    "\n",
    "- *Using LeakyReLU as an activation fn.:* Typically ReLU activations are used in generator function, but using a 'Leaky' version (allowing some slope in the rectified region) proves to be better for higher resolution model. \n",
    "\n",
    "## Training of DCGANs\n",
    "\n",
    "The training will consist of simulatnaeous minibatch gradient descent using Adam for the Discriminator and Generator networks \n",
    "\n",
    "The training statistics that will be reported are as follows:\n",
    "\n",
    "**Loss_D** : The Discriminator loss that is computed over all real and all fake batches of data as:\n",
    "\n",
    "$log\\left(D\\left(\\mathbf{x}\\right)\\right) + log\\left(1 - D\\left(G\\left(\\mathbf{z}\\right)\\right)\\right)$\n",
    "\n",
    "However, for improved training it has been shown by Goodfellow et.al. that minimizing the Generator function using $log\\left(1 - D\\left(G\\left(\\mathbf{z}\\right)\\right)\\right)$ is not efficient in the initial stage, as early in the learning phase $D\\left(G\\left(\\mathbf{z}\\right)\\right)$ is usually close to 0 (since the generator is able to generate samples that look very far from the real), so the loss $log\\left(1 - D\\left(G\\left(\\mathbf{z}\\right)\\right)\\right)$ is close to zero, which means very less updates for the parameters of the $G\\left(\\mathbf{z}\\right)$ through backprop. \n",
    "\n",
    "Instead the function to be optimized could be:\n",
    "\n",
    "$log\\left(D\\left(\\mathbf{x}\\right)\\right) + log\\left(D\\left(G\\left(\\mathbf{z}\\right)\\right)\\right)$\n",
    "\n",
    "**(which sadly is no longer a zero-sum game, but helps train the network better)** (for information on why this called a zero sum game, it is encouraged to consult the problem formulation in the tutorial [1])\n",
    "\n",
    "**Loss_G** -  Generator loss calculated as $log\\left(D\\left(G\\left(\\mathbf{z}\\right)\\right)\\right)$ \n",
    "\n",
    "**D(x), D(G(z))** -  Discriminator Outputs of real and fake samples respectively. Initally, these values will be far apart but will later become very close to 0.5 as G gets better. This will be illustrated graphically and explained analytically later on after training\n",
    "\n",
    "As a future reference, you can consult this repository for certain 'training hacks' concerning GANs: https://github.com/soumith/ganhacks\n",
    "\n",
    "## Interpolating latent space\n",
    "\n",
    "After training the DCGAN, you can examine the quality of the fake images by passing noise as inputs to the **trained** Generator network. Additionally, we can do something more interesting where we can try to see how a fake image of a digit say 1 changes to another digit 2. You will explore this by sampling two noise inputs $\\mathbf{z}_{1}$ and $\\mathbf{z}_{2}$, interpolating them linearly using a parameter $\\rho$ and then looking at the resulting interpolated image by passing the interpolated noise input through the generator. \n",
    "\n",
    "$\\mathbf{z}_{interpolated} = \\rho \\mathbf{z}_{1} + (1 - \\rho) \\mathbf{z}_{2}, \\hspace{0.5 in} \\rho \\in \\left[0, 1\\right]$\n",
    "\n",
    "$\\mathbf{x}_{interpolated} = G\\left(\\mathbf{z}_{interpolated}\\right)$\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this notebook, you will implement a Deep Convolutional Generative Adversarial Network (DCGAN) model on the MNIST dataset and learn to generate real and fake images (using PyTorch). \n",
    "\n",
    "## Tasks\n",
    "\n",
    "The tasks include completing some lines of the code that have been hidden / removed. The description of each subtask is usually present on the cell above the code. Completing the missing code will help in \n",
    "\n",
    "- Implementing the DCGAN network\n",
    "  - Setting up the Generator Network\n",
    "  - Setting up the Discriminator Network\n",
    "- Building the training loop and associated sub-functions\n",
    "- Examining the quality of the reconstructions and then look at results for interpolation of latent space\n",
    "\n",
    "We also suggest you to comment your code wherever possible to increase its readability and also to show your understanding in case you are unsure about something :) \n",
    "\n",
    "## Additional exercises\n",
    "\n",
    "In addition to the coding exercises in the cells, try to answer the following:\n",
    "\n",
    "- Observe the progression of the training and monitor the losses. Do they eventually settle (a bit noisy) around some values ? If they don't, what is such a phenomenon called while training GANs ?\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Goodfellow, Ian. \"NIPS 2016 tutorial: Generative adversarial networks.\" arXiv preprint arXiv:1701.00160 (2016). [(click here)](https://arxiv.org/pdf/1701.00160.pdf])\n",
    "\n",
    "[2] Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015). [(click here)](https://arxiv.org/pdf/1511.06434.pdf%C3)\n",
    "\n",
    "### Additional resources (if required)\n",
    "\n",
    "Also, some helpful code from :\n",
    "\n",
    "DCGAN tutorial on CelebA dataset: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "https://github.com/znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN/blob/master/pytorch_MNIST_DCGAN.py\n",
    "\n",
    "Other varieties of GAN available from :\n",
    "\n",
    "https://github.com/wiseodd/generative-models\n",
    "\n",
    "Consult this repository for certain 'training hacks' concerning GANs: \n",
    "\n",
    "https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7hvCnfctWQk"
   },
   "source": [
    "### Connecting to GPU:\n",
    "\n",
    "- This notebook uitilizes the computational power of GPUs for faster execution. In case your computers have GPU support or access to GPU servers, you do not need to execute this notebook on Google Colab.\n",
    "\n",
    "Otherwise, if you choose to use Google Colab the following steps follow:\n",
    "\n",
    "- In order to facilitate the use of GPUs in Google Colab (owing to large no. of parameters in the models), firstly you can connect to the GPU by going to *Edit* ---> *Notebook settings* ---> Select *Hardware accelerator* as *GPU*. The notebook will reconnect once and will now be connected to the GPU given by Google Colab. If the setting is not changed, then the codes will be executed using CPU.\n",
    "\n",
    "  You can check the GPU status by executing the command in the following cell to check available GPU memory and stats.\n",
    "\n",
    "  ```\n",
    "  !/opt/bin/nvidia-smi # '!' is used to access command line\n",
    "  ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juO1xvP7hTHI"
   },
   "source": [
    "## Check the status of GPU \n",
    "\n",
    "(usually this is the way to do it in case you are using Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHnPLkcrtdqi",
    "outputId": "a58df137-b899-4605-8fb8-941c7007161d"
   },
   "outputs": [],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZQZAwdtk9Q"
   },
   "source": [
    "## **Importing and Loading the Dataset**: \n",
    "\n",
    "The MNIST Dataset involves 60000 training and 10000 testing images of handwritten digits. The images are by default 28 x 28 dimensional images but can be resized. MNIST Dataset is already available to be imported using *torchvision* in PyTorch. But, you can alternatively download the dataset from the official website and import in the code. In any case it will be required to create a **DataLoader** class for batch-wise training and some transforms need to be applied for pre-processing the data such as *Resizing*, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJ5URTrF7CiQ"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import IPython\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEu-5aEsWd6W",
    "outputId": "f8af5da7-8e62-4b9a-d35b-178f337c75bb"
   },
   "outputs": [],
   "source": [
    "# Print out the version of the packages\n",
    "print(\"pytorch=={}\".format(torch.__version__))\n",
    "print(\"torchvision=={}\".format(torchvision.__version__))\n",
    "print(\"numpy=={}\".format(np.__version__))\n",
    "print(\"matplotlib=={}\".format(matplotlib.__version__))\n",
    "print(\"IPython=={}\".format(IPython.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICqcDOjT7fWt",
    "outputId": "5c8c3e56-2872-41b4-918a-181d23900cd9"
   },
   "outputs": [],
   "source": [
    "# Set manual seed for reproducibility\n",
    "#manualSeed = 999\n",
    "manualSeed = np.random.randint(1, 10000) # use if you desire new results\n",
    "print(\"Random seed:{}\".format(manualSeed))\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imLPuKVjt2sE"
   },
   "source": [
    "### Decide on which device you want to run your model\n",
    "\n",
    "(For running on GPU, you might need to change the notebook settings to GPU as discussed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NcWYAaiuCO-",
    "outputId": "41537ddd-430a-48a2-9226-4df4b1e0cb9b"
   },
   "outputs": [],
   "source": [
    "ngpu = 1 # Comment this out if you want to run on cpu and the next line just set device to \"cpu\"\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu>0) else \"cpu\")\n",
    "print(\"Device Used:{}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdYKu9kH7_m-"
   },
   "source": [
    "### Defining some inputs and Importing the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "5773ba599ded4432b78276b88e8ce8f3",
      "86d352fd278e4e2782ded3861ddf8892",
      "bd33130487264f069fbd5953db560ccb",
      "2e53c6d5428f4acda0e67e63a5b0cf34",
      "7fbd2be72dac448cb7a3eccf7136116f",
      "9979ff01dc84426695b0ec3c3235206a",
      "38776c0049a54d5888f0ab4a18fe2d30",
      "bf3dbff7c61d42b197f8b814a4b6c003",
      "794a5f3bcddc495cb8833f6283d1387a",
      "bf7e21f1bcc347f4a2b11d2b544f8be9",
      "758d37275f6b4a6e81e39cc9055b3c09",
      "863c1ba960e442cf85178d395c8d4e2f",
      "507ae6b026a74addb4bb117a0b6baac8",
      "0321db48f3f44c23a31d5242af76157a",
      "46976a6bfe864706a35c1125a6f33f94",
      "a0831cc0a25b450ba3a102f3941eed54",
      "342d7dd3099f44aab9700549ea541d33",
      "c90ade7b55314b27b030ff5d0e459d9a",
      "98aece282fc04932b31d5d12442e2e32",
      "da809db47669419291cd7f1a66046583",
      "253b7fea8ff148c3a8332a7998ea7d31",
      "d3fc5ab1b03a4b38a12e0c3442eb597c",
      "8ba69d15455b42c19dedbe7c994918ad",
      "bbe076044cc94fda97c555cb23cd1d30",
      "df12531db97e43cd8268d3d90bd813da",
      "d0d88a481329452aabbbb87fc178af86",
      "a961e66a859944c39f522bfd1642c270",
      "cf2bf555abc84a4eaf5b295c00e6b101",
      "45f7f4e5ba5648989e72cb9ee5a6960d",
      "c2765feb469e45fb9fb3c33cb9b92a98",
      "0f06c4e422034a35938dc2c32f9bd248",
      "dc1dfa4089244876bf94678efa4cc6f7",
      "20fcac6f36ea439f9b3bc84f936bcdad",
      "ae1943d4dfb045a585a7a0e87282bd62",
      "e9be00dfc7824e759d58758a2928b18e",
      "2b10707c993c422c8a4e9069387c87c7",
      "3fcbb94c086845a8ac585db0c03995ff",
      "242e2fb5efb440ec9b818ba92e477b38",
      "fbcbc9fab0da4cca80749f617f86f1e9",
      "2ebdb59d3dc64134becbc482e3c686e6",
      "4b4b6c6f6e9e440da4f1bc88490c6650",
      "b0ac493bc3fb4e4ca21910eb14a8bde6",
      "bdbb29033bd44ddd8255d52e2f10d4c3",
      "8644a7e8d9ef4841bcccf92306e5f391"
     ]
    },
    "id": "gLN20GuC8HK5",
    "outputId": "8cc9f22c-7f9a-4a1e-a636-e1cd22708f87"
   },
   "outputs": [],
   "source": [
    "img_size = 28 # As MNIST dataset consists of 28 x 28 images\n",
    "# When downloading the dataset using torchvision for the first time, set the 'download' option to be\n",
    "# True, henceforward set the option to be False\n",
    "\n",
    "# Change the saving location accordingly as you like, in this case this has been\n",
    "# set to '/sample_data/MNIST_data/'\n",
    "mnist_trainset = datasets.MNIST('./sample_data/MNIST_data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([transforms.Resize((img_size, img_size)),\n",
    "                                                                       transforms.ToTensor(),\n",
    "                                                                       transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                                                                       ]))\n",
    "mnist_testset = datasets.MNIST('./sample_data/MNIST_data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([transforms.Resize((img_size, img_size)),\n",
    "                                                                       transforms.ToTensor(),\n",
    "                                                                       transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                                                                       ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "khMqwagN-jlz",
    "outputId": "49ab06c8-2f94-4d54-ccc0-f0daac6564ff"
   },
   "outputs": [],
   "source": [
    "# For loading the data in batches using DataLoader (also motivated as per [2])\n",
    "# All training images will be resized to this dimension, Here in MNIST, \n",
    "# images are (28 x 28) in spatial dimensions\n",
    "batch_size = 128 \n",
    "image_size = 28 \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8, 8)) # As the training images are of size (28 x 28)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], \n",
    "                                         padding=2, normalize=True).cpu(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5vbCyveNiFi",
    "outputId": "f1ecad03-cc54-4d76-9431-600a69a02101"
   },
   "outputs": [],
   "source": [
    "# Check spatial dimensions of a batch of training samples and \n",
    "# some basic statistics like mean, minimum and maximum value\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_data.dtype)\n",
    "print(example_data.min())\n",
    "print(example_data.mean())\n",
    "print(example_data.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_BZw59TulkK"
   },
   "source": [
    "### Define the Network parameters and Optimizer parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG7mZF8p8aK7"
   },
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Network Parameters\n",
    "############################################################################################\n",
    "\n",
    "nc = 1 # No. of color channels used in the training image\n",
    "ngf = 64 # Depth of feature maps carried forward in generator network\n",
    "ndf = 16 # Depth of feature maps carried forward in discriminator network\n",
    "nz = 64 # Size of the generator latent variable ('Flattened' dimension size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH2AvMaqHhTW"
   },
   "source": [
    "## **Building the Generator and Discriminator networks for DCGAN**\n",
    "\n",
    "Implementation of the Generator and Discriminator of the DCGAN. In this case we will be implementing the DCGAN architecture, which consists of using a specific random initialisation of weights, followed by defining the convolutional neural networks for the Generator function and the Discriminator function. An example of how a Generator network would look like is provided as a block diagram in [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKBTIcilSWfa"
   },
   "source": [
    "### Defining a function for weight initialisation for the generator and discriminator networks. \n",
    "\n",
    "As per the paper on DCGAN [2], the weights shall be initialised as normally distributed with parameters: mean=0, stdev=0.02. \n",
    "\n",
    "#### **Task:**\n",
    "Use `nn.init` and the `normal_` function there to initialise layer weights of the convolutional layers using normallly distributed values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m3IKH2gC5Bz"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "#    This function takes in a module 'm' as an input and initialises the \n",
    "#    weights of the module. In this case, the modules are mostlly convolutional\n",
    "#    layers\n",
    "#    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        ### ... Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m74jd9leJQ5E"
   },
   "source": [
    "### Setting up the Generator network for the DCGAN:\n",
    "\n",
    "The Generator Network $G\\left(z\\right)$ is designed to map the latent space vector $(z)$ to the data-space. \n",
    "\n",
    "By doing so, the intention should be produce data samples that are designed to confuse the Discriminator Network. \n",
    "\n",
    "Additionally, a Generator network uses strided convolutions, each paired with a Batch-Normalization layer and a ReLU activation. The generator output is passed through a *tanh* function to return it in the range $\\left[-1, 1\\right]$. \n",
    "\n",
    "For a guide on how to use ConvTranspose2D (which is basically the opposite operation of Conv2D): https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d\n",
    "\n",
    "For a guide on how to use BatchNorm: \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVPyW41QeKvq"
   },
   "outputs": [],
   "source": [
    "# Defining a function for creating basic blocks for the Generator Network\n",
    "\n",
    "def create_Gen_block_basic(n_in, n_out, kernel_size, stride, padding, bias=False):\n",
    "    \"\"\" \n",
    "    Creating a basic block for the DCGAN generator network.\n",
    "    A basic block for the DCGAN generator consists of three layers one after the \n",
    "    other in a sequential manner (achieved using nn.Sequential()). Those three layers\n",
    "    are: \n",
    "      - A Transposed Convolutional layer (can be thought of as an inverse of the convolution operation)\n",
    "      - A Batch normalization layer \n",
    "      - A ReLU activation function\n",
    "\n",
    "    Args:\n",
    "    - n_in: No. of input channels\n",
    "    - n_out: No. of output channels\n",
    "    - kernel_size: Kernel size of the filter / kernel used for convolution\n",
    "    - stride: No. of pixels by which the kernel is to be shifted\n",
    "    - padding: Padding to be added to the input before convolution\n",
    "    - bias: Flag to decide whether to include bias in the convolution layer\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=n_in, out_channels=n_out, kernel_size=kernel_size,\n",
    "                           stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(num_features=n_out),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# Defining a function the last block for the Generator Network\n",
    "\n",
    "def create_Gen_block_last(n_in, n_out, kernel_size, stride, padding, bias=False):\n",
    "    \"\"\" \n",
    "    Creating the last block for the DCGAN generator network.\n",
    "    The last block for the DCGAN generator consists of two layers one after the \n",
    "    other in a sequential manner (achieved using nn.Sequential()). Those two layers\n",
    "    are: \n",
    "      - A Transposed Convolutional layer (can be thought of as an inverse of the convolution operation)\n",
    "      - A tanh activation function\n",
    "      \n",
    "    Args:\n",
    "    - n_in: No. of input channels\n",
    "    - n_out: No. of output channels\n",
    "    - kernel_size: Kernel size of the filter / kernel used for convolution\n",
    "    - stride: No. of pixels by which the kernel is to be shifted\n",
    "    - padding: Padding to be added to the input before convolution\n",
    "    - bias: Flag to decide whether to include bias in the convolution layer\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=n_in, out_channels=n_out, kernel_size=kernel_size,\n",
    "                           stride=stride, padding=padding, bias=False),\n",
    "        nn.Tanh()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh1xvOHDeKHn"
   },
   "outputs": [],
   "source": [
    "class Gen_network(nn.Module):\n",
    "    \"\"\"\n",
    "    This function utilizes the basic block building functions defined as above\n",
    "    and builds the total network by sequentially stacking up the blocks \n",
    "    using nn.Sequential(). The values passsed to the individual block creating \n",
    "    functions are decided based on the input to that block and the expected shape of the \n",
    "    output (also mentioned as 'Output size')\n",
    "    ----\n",
    "    Args:\n",
    "      - nz: Size of the hidden layer\n",
    "      - ngf: Depth of feature maps carried forward in generator network\n",
    "      - nc: Number of channels expected in the output\n",
    "      - ngpu: Number of gpu threads available for use, usually set this to 1\n",
    "\n",
    "    Methods:\n",
    "      - __init__(): Initializes the network \n",
    "      - forward(): Performs a simple forward pass through the network\n",
    "    \"\"\"\n",
    "    def __init__(self, nz=64, ngf=64, nc=1, ngpu=1):\n",
    "        super(Gen_network, self).__init__()\n",
    "        \n",
    "        self.ngpu = ngpu # No. of GPU threads available for use\n",
    "        \n",
    "        self.main = nn.Sequential()\n",
    "        \n",
    "        # Input is Z (tensor of shape (batch size x nz x 1 x 1)) and will be transformed \n",
    "        # into a convolution\n",
    "        self.main.add_module('genblock1', create_Gen_block_basic(n_in=nz, n_out=ngf*4, kernel_size=3,\n",
    "                                                    stride=2, padding=0, bias=False))\n",
    "\n",
    "         # State size. (ngf * 4) x 3 x 3 (i.e. num_channels = ngf*4, kernel_size = (3, 3))\n",
    "        self.main.add_module('genblock2', create_Gen_block_basic(n_in=ngf*4, n_out=ngf*2, kernel_size=4,\n",
    "                                                    stride=1, padding=0, bias=False))\n",
    "        \n",
    "        # State size. (ngf * 2) x 6 x 6 (i.e. num_channels = ngf*2, kernel_size = (6, 6))\n",
    "        self.main.add_module('genblock3', create_Gen_block_basic(n_in=ngf*2, n_out=ngf, kernel_size=3,\n",
    "                                                    stride=2, padding=0, bias=False))\n",
    "        \n",
    "        # State size. (ngf) x 13 x 13 (i.e. num_channels = ngf, kernel_size = (13, 13))\n",
    "        self.main.add_module('genblock_last', create_Gen_block_last(n_in=ngf, n_out=nc, kernel_size=4,\n",
    "                                                    stride=2, padding=0, bias=False))\n",
    "        # State size. (nc) x 28 x 28\n",
    "  \n",
    "    def forward(self, input):\n",
    "        return self.main(input) # Returns the output of the generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6028GMtZXLZS"
   },
   "source": [
    "### Setting up the Discriminator Network for the DCGAN: \n",
    "The Discriminator Function $D\\left(x\\right)$ is a binary classification network that takes an image as an input and outputs a scalar probability that the input image is real (as opposed to fake). \n",
    "\n",
    "Here, $D\\left(x\\right)$ takes a nc x 64 x 64 image as an input and processes it through a series of Conv2D layers (as opposed to ConvTransposed2D layers in case of $G\\left(z\\right)$.\n",
    "\n",
    "**Task**: \n",
    "- Similar to the generator network, complete the code for creating basic blocks of the discriminator network. \n",
    "- The last block of the Discriminator network is to contain **no batch normalization** and should use a **sigmoid** activation. Use `nn.Sequential( )` in the similar way as in `create_Disc_block_basic( )` and `create_Disc_block_last( )`\n",
    "- Also, there are Batch Normalization and LeakyReLU (with a slope of 0.2) layers applied afeter every Conv2D layer as in previous case. So each Disc. block consists of Conv2D, Batchnorm, LeakyReLU layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "en_neyPahdzD"
   },
   "outputs": [],
   "source": [
    "# Defining a function for creating basic blocks for the Discriminator Network\n",
    "\n",
    "def create_Disc_block_basic(n_in, n_out, kernel_size, stride, padding, bias=False):\n",
    "    \"\"\" \n",
    "    Creating a basic block for the DCGAN discriminator network.\n",
    "    A basic block for the DCGAN discriminator consists of three layers one after the \n",
    "    other in a sequential manner (achieved using nn.Sequential()). Those three layers\n",
    "    are: \n",
    "      - A Convolutional layer \n",
    "      - A Batch normalization layer \n",
    "      - A LeakyReLU activation function\n",
    "\n",
    "    Args:\n",
    "    - n_in: No. of input channels\n",
    "    - n_out: No. of output channels\n",
    "    - kernel_size: Kernel size of the filter / kernel used for convolution\n",
    "    - stride: No. of pixels by which the kernel is to be shifted\n",
    "    - padding: Padding to be added to the input before convolution\n",
    "    - bias: Flag to decide whether to include bias in the convolution layer\n",
    "    \"\"\"\n",
    "    # Insert Code here\n",
    "    # ...\n",
    "      \n",
    "\n",
    "# Defining a function the last block for the Discriminator Network\n",
    "\n",
    "def create_Disc_block_last(n_in, n_out, kernel_size, stride, padding, bias=False):\n",
    "    \"\"\"\n",
    "    Creating the last block for the DCGAN discriminator network.\n",
    "    The last block for the DCGAN discriminator consists of two layers one after the \n",
    "    other in a sequential manner (achieved using nn.Sequential()). Those two layers\n",
    "    are: \n",
    "      - A Convolutional layer (can be thought of as an inverse of the convolution operation)\n",
    "      - A sigmoid activation function\n",
    "      \n",
    "    Args:\n",
    "    - n_in: No. of input channels\n",
    "    - n_out: No. of output channels\n",
    "    - kernel_size: Kernel size of the filter / kernel used for convolution\n",
    "    - stride: No. of pixels by which the kernel is to be shifted\n",
    "    - padding: Padding to be added to the input before convolution\n",
    "    - bias: Flag to decide whether to include bias in the convolution layer\n",
    "    \"\"\"\n",
    "    # Insert Code here\n",
    "    # ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CRZrc9lhTHN"
   },
   "source": [
    "**Task**: Now using the functions for creating the basic blocks, create the Discriminator network in the similar manner as the Generator network. Pay attention to input and output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWf7jSsLh3t6"
   },
   "outputs": [],
   "source": [
    "class Discr_network(nn.Module):\n",
    "    \"\"\"\n",
    "    This function utilizes the basic block building functions defined as above\n",
    "    and builds the total discriminator network by sequentially stacking up the blocks \n",
    "    using nn.Sequential(). The values passsed to the individual block creating \n",
    "    functions are decided based on the input to that block and the expected shape of the \n",
    "    output (also mentioned as 'Output size')\n",
    "    ----\n",
    "    Args:\n",
    "      - nz: Size of the hidden layer\n",
    "      - ndf: Depth of feature maps carried forward in discriminator network \n",
    "      - nc: Number of channels expected in the output\n",
    "      - ngpu: Number of gpu threads available for use, usually set this to 1\n",
    "\n",
    "    Methods:\n",
    "      - __init__(): Initializes the network \n",
    "      - forward(): Performs a simple forward pass through the network\n",
    "    \"\"\"\n",
    "    def __init__(self, ndf=16, nc=1, ngpu=1):\n",
    "        super(Discr_network, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential()\n",
    "        \n",
    "        # Input is a tensor of dimension (batch_size x nc x 28 x 28)\n",
    "        self.main.add_module('discblock1', create_Disc_block_basic(n_in=nc, n_out=ndf, kernel_size=4,\n",
    "                                                     stride=2, padding=0, bias=False))\n",
    "        \n",
    "        ##########################################################################\n",
    "        # Fill in the dimensions for the kernel_size, stride and padding parameter\n",
    "        # s.t. the resulting output has  spatial dimensions are 5 x 5, and the  \n",
    "        # number of output channels is ndf * 2 (try using padding=0, and find the \n",
    "        # kernel size and stride)\n",
    "        ##########################################################################\n",
    "        self.main.add_module('discblock2', # ... Insert Code here)\n",
    "        \n",
    "        ##########################################################################\n",
    "        # Fill in the dimensions for the kernel_size, stride and padding parameter\n",
    "        # s.t. the resulting output has spatial dimensions are 1 x 1, and the \n",
    "        # number of output channels is 1 (as the output is a single tensor)\n",
    "        # (try using padding=0, and find the kernel size and stride)\n",
    "        ##########################################################################\n",
    "        self.main.add_module('discblock_last', # ... Insert Code here)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E74KDdOasDf"
   },
   "source": [
    "Create the Generator and Discriminator Network and initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5LlFmoNakZk",
    "outputId": "6bb284c5-8eab-41c3-ff4a-694437879fe5"
   },
   "outputs": [],
   "source": [
    "G_net = Gen_network(nz, ngf, nc, ngpu).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialise all the weights \n",
    "# to mean = 0 and stddev = 0.02\n",
    "G_net.apply(weights_init)\n",
    "\n",
    "# Pushing the model to the GPU\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    G_net = nn.DataParallel(G_net, list(range(ngpu)))\n",
    "elif (device.type == 'cuda') and (ngpu == 1):\n",
    "    G_net.cuda()\n",
    "\n",
    "# Print the Model\n",
    "print(G_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0giqLf63bsnp",
    "outputId": "8b6a17f2-2eab-4cfd-f410-0409fc87664c"
   },
   "outputs": [],
   "source": [
    "D_net = Discr_network(ndf=ndf, nc=nc, ngpu=ngpu)\n",
    "\n",
    "# Apply the weights_init function to randomly initialise all the weights \n",
    "# to mean = 0 and stddev = 0.02\n",
    "D_net.apply(weights_init)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    D_net = nn.DataParallel(D_net, list(range(ngpu)))\n",
    "elif (device.type == 'cuda') and (ngpu == 1):\n",
    "    D_net.cuda()\n",
    "\n",
    "# Print the Model\n",
    "print(D_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTa357cWgLEq"
   },
   "source": [
    "### Set up loss function and optimizers for Discriminator and Generator\n",
    "\n",
    "The choces for most training parameters such as the type of Optimizer used, learning rate, momentum are as per the recommendations in [2]. It was found that using *Adam* as an optimizer, a low learning rate as 0.0002 and a slightly less momentum value such as 0.5 helped to deal with instability problems in training. The loss function used is a binary Cross Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFOyJ2mlfv7v",
    "outputId": "87eefe13-ee82-4d1f-df6b-a37ad2a65656"
   },
   "outputs": [],
   "source": [
    "# Initialise Binary Cross Entropy Loss to be used for the Discriminator function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer Parameters\n",
    "lr = 0.0002 # Learning rate of the optimizer (Recommended learning rate as per [2])\n",
    "beta1 = 0.5 # Hyperparametr of for Adam optimizer (Recommended Momentum value as per [2])\n",
    "ngpu = 1 # Number of GPUs available for training. \n",
    "\n",
    "# Create a batch of latent vectors that will be used as input to the generator network \n",
    "# This set of vectors will be used to save some outputs for visualising the quality of the\n",
    "# generated samples later on in an 8 x 8 grid\n",
    "fixed_noise = Variable(torch.randn(64, nz, 1, 1, device=device), requires_grad=False)\n",
    "print(fixed_noise.dtype)\n",
    "\n",
    "# Establish labels for 'Real' and 'Fake' (Generated) data during training\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(D_net.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(G_net.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ygf57z4hN48"
   },
   "source": [
    "## **Building the training loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV45dRIxhTHO"
   },
   "source": [
    "**Task:** Complete the code for the associated update functions by filling in the remaining areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKRK4uWEorbp"
   },
   "outputs": [],
   "source": [
    "def update_D_net(data, D_net, G_net, optimizer_D, real_label, fake_label, criterion, device):\n",
    "    '''\n",
    "    Update D network: maximize 0.5 * (log(D(x)) + log(D(G(z)))) wrt parameters of D_net\n",
    "   \n",
    "    - data: A batch of real data as input. Consists of (inputs, labels) in a batch-size\n",
    "    - D_net: The discriminator network\n",
    "    - G_net: The generator network\n",
    "    - optmizer_D: The optimizer for the discriminative network\n",
    "    - real_label: The real label for the output of the discriminative network (usually this is 1.0)\n",
    "    - fake_label: The fake label for the output of the discriminative network (usually this is 0.0)\n",
    "    - criterion: The binary cross entropy loss function used for formulating 0.5 * (log(D(x)) + log(D(G(z))))\n",
    "    - device: The device to push networks, tensors (cpu/cuda (gpu))\n",
    "    '''\n",
    "    \n",
    "    ##############################################################\n",
    "    ## Train with all-'real' batch (finding log(D(x)))\n",
    "    ##############################################################\n",
    "    \n",
    "    D_net.zero_grad()\n",
    "    # Format batch\n",
    "    real = data[0].to(device)\n",
    "    b_size = real.size(0)\n",
    "    label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "    # Forward pass real batch through D\n",
    "    output = D_net(real).view(-1)\n",
    "    # Calculate loss on all-real batch\n",
    "    errD_real = criterion(output, label)\n",
    "    # Calculate gradients for D in backward pass\n",
    "    errD_real.backward(retain_graph=True)\n",
    "    D_x = output.mean().item()\n",
    "\n",
    "    ##############################################################\n",
    "    ## Train with all-'fake' batch log(D(G(z)))\n",
    "    ##############################################################\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "    # Generate fake image batch with G\n",
    "    fake = G_net(noise)\n",
    "    label.fill_(fake_label)\n",
    "    # Classify all fake batch with D\n",
    "    output = D_net(fake.detach()).view(-1)\n",
    "    # Calculate D's loss on the all-fake batch\n",
    "    errD_fake = criterion(output, label)\n",
    "    # Calculate the gradients for this batch\n",
    "    errD_fake.backward(retain_graph=True)\n",
    "    D_G_z1 = output.mean().item() # Output 'before' an update of the discriminator\n",
    "    \n",
    "    ##########################################################################\n",
    "    # Add the average of the gradients from the all-real and all-fake batches\n",
    "    # to compute the error for the Disc. network\n",
    "    ##########################################################################\n",
    "    errD = (errD_real + errD_fake)*0.5\n",
    "\n",
    "    # Update the Disc. network\n",
    "    optimizerD.step()\n",
    "\n",
    "    return D_x,  D_G_z1, errD, D_net, fake\n",
    "\n",
    "def update_G_net(data, fake, D_net, G_net, optimizer_G, real_label, criterion, device):\n",
    "    '''\n",
    "    Update G network: maximize log(D(G(z)))) wrt to parameters of G_net\n",
    "    NOTE: This is no longer a zero-sum game.\n",
    "    \n",
    "    - data: A batch of real data as input. Consists of (inputs, labels) in a batch-size\n",
    "    - fake: A batch of fake data generated from noisy input and G_net\n",
    "    - D_net: The discriminator network\n",
    "    - G_net: The generator network\n",
    "    - optmizer_G: The optimizer for the discriminative network\n",
    "    - real_label: The real label for the output of the discriminative network (usually this is 1.0)\n",
    "    - criterion: The binary cross entropy loss function used for formulating 0.5 * (log(D(x)) + log(D(G(z))))\n",
    "    - device: The device to push networks, tensors (cpu/cuda (gpu))\n",
    "    '''\n",
    "    ##################################################################\n",
    "    # (2) Update G network: maximize log(D(G(z)))\n",
    "    ##################################################################\n",
    "    \n",
    "    real = data[0].to(device)\n",
    "    b_size = real.size(0)\n",
    "    label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "    G_net.zero_grad()\n",
    "    \n",
    "    label.fill_(real_label)  # fake labels are considered 'real' for generator cost\n",
    "    \n",
    "    # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "    output = # ... Insert Code here\n",
    "    # Calculate G's loss based on this output\n",
    "    errG = # ... Insert Code here\n",
    "    # Calculate gradients for G\n",
    "    errG.backward(retain_graph=True)\n",
    "    D_G_z2 = # ... Insert Code here # Output 'after' an update of the discriminator\n",
    "\n",
    "    # Update the Gen. network by calling the optimizer\n",
    "    # ... Insert code here \n",
    "\n",
    "    return D_G_z2, errG, D_net, G_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CbM66ZohTHO"
   },
   "source": [
    "**Task:** Complete the code for the training loop by filling in the remaining areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJRd-q-CsHaR"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 20 # No. of training epochs\n",
    "\n",
    "def train_GAN(D_net, G_net, train_loader, optimizer_D, optimizer_G, criterion, \n",
    "              device, real_label=1.0, fake_label=0.0, num_epochs=20, fixed_noise=None):\n",
    "    \n",
    "    # Lists to keep track of the training progress\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    D_x_values = []\n",
    "    D_Gz_values = []\n",
    "    iters = 0\n",
    "    \n",
    "    print(\"Starting Training Loop...\")\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # For each batch in the dataloader\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            ################################################################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            # by calling update_D_net(). Check for input arguments by \n",
    "            # looking at the calling function for update_D_net()\n",
    "            ###############################################################\n",
    "            \n",
    "            D_x, D_G_z1, errD, D_net, fake = # ... # Insert Code here\n",
    "\n",
    "            #######################################################################\n",
    "            # (2) Update G network: maximize log(D(G(z))) by calling update_G_net()\n",
    "            # Check for input arguments by looking at the calling function for \n",
    "            # update_G_net()\n",
    "            #######################################################################\n",
    "\n",
    "            D_G_z2, errG, D_net, G_net = # ... # Insert code here\n",
    "            \n",
    "            # Output training stats: D_x reflects the discriminator output after passing in \n",
    "            # the real input, D_G_z1 represents the discriminator output after passing in the\n",
    "            # generated output BEFORE update of discriminator, whereas D_G_z2 represents the \n",
    "            # discriminator output after passing in the generated output AFTER\n",
    "            # update of discriminator\n",
    "            if i % 400 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, num_epochs, i, len(train_loader),\n",
    "                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "            D_x_values.append(D_x)\n",
    "            D_Gz_values.append(D_G_z2)\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = G_net(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "            iters += 1\n",
    "      \n",
    "\n",
    "    return D_net, G_net, D_losses, G_losses, D_x_values, D_Gz_values, img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaNWOpwewlZe",
    "outputId": "9c4f14a8-c10d-4d45-dc40-74e337d2a6e4"
   },
   "outputs": [],
   "source": [
    "D_net, G_net, D_losses, G_losses, D_x_values, D_Gz_values, img_list = train_GAN(D_net,\n",
    "                                                                                G_net, \n",
    "                                                                                train_loader,\n",
    "                                                                                optimizerD,\n",
    "                                                                                optimizerG,\n",
    "                                                                                criterion,\n",
    "                                                                                device,\n",
    "                                                                                real_label,\n",
    "                                                                                fake_label,\n",
    "                                                                                num_epochs,\n",
    "                                                                                fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ce5enqwneEu"
   },
   "source": [
    "Plotting the losses for the generator and the discriminator network (usually a bit noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "5VH1646LpZFS",
    "outputId": "96805228-9cef-4644-8895-d25e482da9e4"
   },
   "outputs": [],
   "source": [
    "# Plotting the losses for the network\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmpkLfFKnkdu"
   },
   "source": [
    "Plotting the values of $D(x)$ and $D(G(z))$ for the network. \n",
    "\n",
    "Could you understand why the graph looks the way it is? (*Think*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "PoFad_Sd9d2h",
    "outputId": "e1e43a17-1da1-4235-c903-20753006e423"
   },
   "outputs": [],
   "source": [
    "# Plotting the values of D(x) and D(G(z)) for the network\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Discriminator outputs D(x) and D(G(z)) during training\")\n",
    "plt.plot(D_x_values,label=\"D(x)\")\n",
    "plt.plot(D_Gz_values,label=\"D(G(z)\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieAApgsynlgs"
   },
   "source": [
    "This animation shows how the generator network produces 'fake' images to confuse the discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tCANb34puBWT",
    "outputId": "016d3620-667c-4be8-be52-e45a2fa13070"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8uR7h5c6IYZ"
   },
   "source": [
    "## **Examining the quality of reconstructions: Looking at some Real Images vs. Fake Images**\n",
    "\n",
    "For the fake images, they don't necessarily correspond to be the exact same digits, rather here the aim is to try to visualise the quality of the fake images that the network uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "wWuO1C-x55yp",
    "outputId": "1411d8f3-fac7-48a2-976c-7666a6b4c844"
   },
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(test_loader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], \n",
    "                                         padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVeiiX3mhTHP"
   },
   "source": [
    "## Interpolating latent space\n",
    "\n",
    "**Task:** In this final task, you generate some interpolated latent space images. For this, you need to generate 2 samples of input noises. Then you need to interpolate them linearly using a parameter $\\rho$ between 0 and 1 and pass the result through the generator network. \n",
    "\n",
    "But in order to observe a smooth transition like grid, we generate an array of parameters and then generate a grid of images, one for each $\\rho$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC0fWJxCC5Ch",
    "outputId": "5348e17a-baf3-4752-e18a-adaacbdbaee6"
   },
   "outputs": [],
   "source": [
    "test_fixed_noise = Variable(torch.randn(2, nz, 1, 1, device=device), requires_grad=False)\n",
    "print(test_fixed_noise.dtype)\n",
    "\n",
    "def interpolate_points(z1, z2, n_steps=10):\n",
    "    '''\n",
    "    Compute the interpolated latent data point using z1 and z2, with rho\n",
    "    varying from [0, 1] with `n_steps` values of rho. Returns a list of \n",
    "    `n_steps` number of latent data points. \n",
    "    '''\n",
    "    rho_vec = torch.linspace(start=0, end=1, steps=n_steps)\n",
    "    latent_vecs = []\n",
    "    for rho in rho_vec:\n",
    "        # Compute the interpolated latent data point between z1 and z2\n",
    "        interpolated_z = # ... Insert Code here \n",
    "        latent_vecs.append(interpolated_z)\n",
    "      \n",
    "    return latent_vecs\n",
    "\n",
    "def get_interpolated_images(G_net, nz, n_steps=10):\n",
    "    '''\n",
    "    Compute the interpolated image corresponding to the latent data point \n",
    "    using z1 and z2, with rho varying from [0, 1] with `n_steps` values of rho. \n",
    "    Returns a list of `n_steps` number of latent data points. \n",
    "    '''\n",
    "    test_fixed_noise = Variable(torch.randn(2, nz, 1, 1, device=device), requires_grad=False)\n",
    "    z1 = test_fixed_noise[0]\n",
    "    z2 = test_fixed_noise[1]\n",
    "    # Get the list of interpolated latent points using the function\n",
    "    # interpolate_points( )\n",
    "    interpolated_z_vecs = # ... Insert code here\n",
    "    image_vecs = []\n",
    "\n",
    "    G_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for interpolated_z in interpolated_z_vecs:\n",
    "            interpolated_z = interpolated_z.view(-1, nz, 1, 1)\n",
    "            # Obtain the corresponding interpolated image\n",
    "            interpolated_x = # ... Insert code here\n",
    "            image_vecs.append(interpolated_x.squeeze(1).squeeze(0).cpu().numpy())\n",
    "    \n",
    "    return image_vecs\n",
    "\n",
    "def plot_generated(examples, n):\n",
    "    '''\n",
    "    Create a plot of generated images using interpolated examples\n",
    "    '''\n",
    "    # plot images\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(n):\n",
    "        # define subplot\n",
    "        plt.subplot(1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "TgHDs535LJL8",
    "outputId": "72354c3b-603f-4cce-b7e0-6139d3b86c7e"
   },
   "outputs": [],
   "source": [
    "# Examine the interpolated images. \n",
    "num_rows = 1 # You can even try to use more than 2 rows to get multiple examples\n",
    "\n",
    "for _ in range(num_rows):\n",
    "    image_vecs = get_interpolated_images(G_net=G_net, nz=nz, n_steps=10)\n",
    "    plot_generated(examples=image_vecs, n=len(image_vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtA6v64SODhf"
   },
   "source": [
    "## Additional tasks: \n",
    "\n",
    "Observe the progression of the training and monitor the losses. Do they eventually settle (a bit noisy) around some values ? If they don't, what is such a phenomenon called while training GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9tf06gNhTHP"
   },
   "source": [
    "Write your answer in this Markdown cell"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN_Question_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0321db48f3f44c23a31d5242af76157a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c90ade7b55314b27b030ff5d0e459d9a",
      "placeholder": "",
      "style": "IPY_MODEL_342d7dd3099f44aab9700549ea541d33",
      "value": ""
     }
    },
    "0f06c4e422034a35938dc2c32f9bd248": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20fcac6f36ea439f9b3bc84f936bcdad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "242e2fb5efb440ec9b818ba92e477b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8644a7e8d9ef4841bcccf92306e5f391",
      "placeholder": "",
      "style": "IPY_MODEL_bdbb29033bd44ddd8255d52e2f10d4c3",
      "value": " 5120/? [00:00&lt;00:00, 8185.36it/s]"
     }
    },
    "253b7fea8ff148c3a8332a7998ea7d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b10707c993c422c8a4e9069387c87c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ebdb59d3dc64134becbc482e3c686e6",
      "placeholder": "",
      "style": "IPY_MODEL_fbcbc9fab0da4cca80749f617f86f1e9",
      "value": ""
     }
    },
    "2e53c6d5428f4acda0e67e63a5b0cf34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794a5f3bcddc495cb8833f6283d1387a",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf3dbff7c61d42b197f8b814a4b6c003",
      "value": 9912422
     }
    },
    "2ebdb59d3dc64134becbc482e3c686e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "342d7dd3099f44aab9700549ea541d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38776c0049a54d5888f0ab4a18fe2d30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fcbb94c086845a8ac585db0c03995ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0ac493bc3fb4e4ca21910eb14a8bde6",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b4b6c6f6e9e440da4f1bc88490c6650",
      "value": 4542
     }
    },
    "45f7f4e5ba5648989e72cb9ee5a6960d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46976a6bfe864706a35c1125a6f33f94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da809db47669419291cd7f1a66046583",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98aece282fc04932b31d5d12442e2e32",
      "value": 28881
     }
    },
    "4b4b6c6f6e9e440da4f1bc88490c6650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "507ae6b026a74addb4bb117a0b6baac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5773ba599ded4432b78276b88e8ce8f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd33130487264f069fbd5953db560ccb",
       "IPY_MODEL_2e53c6d5428f4acda0e67e63a5b0cf34",
       "IPY_MODEL_7fbd2be72dac448cb7a3eccf7136116f"
      ],
      "layout": "IPY_MODEL_86d352fd278e4e2782ded3861ddf8892"
     }
    },
    "758d37275f6b4a6e81e39cc9055b3c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "794a5f3bcddc495cb8833f6283d1387a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fbd2be72dac448cb7a3eccf7136116f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_758d37275f6b4a6e81e39cc9055b3c09",
      "placeholder": "",
      "style": "IPY_MODEL_bf7e21f1bcc347f4a2b11d2b544f8be9",
      "value": " 9913344/? [00:00&lt;00:00, 18467489.68it/s]"
     }
    },
    "863c1ba960e442cf85178d395c8d4e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0321db48f3f44c23a31d5242af76157a",
       "IPY_MODEL_46976a6bfe864706a35c1125a6f33f94",
       "IPY_MODEL_a0831cc0a25b450ba3a102f3941eed54"
      ],
      "layout": "IPY_MODEL_507ae6b026a74addb4bb117a0b6baac8"
     }
    },
    "8644a7e8d9ef4841bcccf92306e5f391": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86d352fd278e4e2782ded3861ddf8892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ba69d15455b42c19dedbe7c994918ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df12531db97e43cd8268d3d90bd813da",
       "IPY_MODEL_d0d88a481329452aabbbb87fc178af86",
       "IPY_MODEL_a961e66a859944c39f522bfd1642c270"
      ],
      "layout": "IPY_MODEL_bbe076044cc94fda97c555cb23cd1d30"
     }
    },
    "98aece282fc04932b31d5d12442e2e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9979ff01dc84426695b0ec3c3235206a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0831cc0a25b450ba3a102f3941eed54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3fc5ab1b03a4b38a12e0c3442eb597c",
      "placeholder": "",
      "style": "IPY_MODEL_253b7fea8ff148c3a8332a7998ea7d31",
      "value": " 29696/? [00:00&lt;00:00, 8452.26it/s]"
     }
    },
    "a961e66a859944c39f522bfd1642c270": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20fcac6f36ea439f9b3bc84f936bcdad",
      "placeholder": "",
      "style": "IPY_MODEL_dc1dfa4089244876bf94678efa4cc6f7",
      "value": " 1649664/? [00:00&lt;00:00, 3411463.72it/s]"
     }
    },
    "ae1943d4dfb045a585a7a0e87282bd62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b10707c993c422c8a4e9069387c87c7",
       "IPY_MODEL_3fcbb94c086845a8ac585db0c03995ff",
       "IPY_MODEL_242e2fb5efb440ec9b818ba92e477b38"
      ],
      "layout": "IPY_MODEL_e9be00dfc7824e759d58758a2928b18e"
     }
    },
    "b0ac493bc3fb4e4ca21910eb14a8bde6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbe076044cc94fda97c555cb23cd1d30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd33130487264f069fbd5953db560ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38776c0049a54d5888f0ab4a18fe2d30",
      "placeholder": "",
      "style": "IPY_MODEL_9979ff01dc84426695b0ec3c3235206a",
      "value": ""
     }
    },
    "bdbb29033bd44ddd8255d52e2f10d4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf3dbff7c61d42b197f8b814a4b6c003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf7e21f1bcc347f4a2b11d2b544f8be9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2765feb469e45fb9fb3c33cb9b92a98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c90ade7b55314b27b030ff5d0e459d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf2bf555abc84a4eaf5b295c00e6b101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0d88a481329452aabbbb87fc178af86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f06c4e422034a35938dc2c32f9bd248",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2765feb469e45fb9fb3c33cb9b92a98",
      "value": 1648877
     }
    },
    "d3fc5ab1b03a4b38a12e0c3442eb597c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da809db47669419291cd7f1a66046583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc1dfa4089244876bf94678efa4cc6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df12531db97e43cd8268d3d90bd813da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f7f4e5ba5648989e72cb9ee5a6960d",
      "placeholder": "",
      "style": "IPY_MODEL_cf2bf555abc84a4eaf5b295c00e6b101",
      "value": ""
     }
    },
    "e9be00dfc7824e759d58758a2928b18e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbcbc9fab0da4cca80749f617f86f1e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
